{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Scenario MORDM\n",
    "\n",
    "Multi-scenario MORMD is an extension of normal MORDM to better include robustness considerations within the search phase. It starts from the scenario discovery results resulting from MORDM. Next, from the experiments within this box, a set of scenarios is selected. \n",
    "\n",
    "There are many ways of selecting the additional scenarios. The original paper which introduced multi-scenario MORMD [Watson and Kaspzryk (2017)](https://doi.org/10.1016/j.envsoft.2016.12.001) did it in a more or less adhoc manner. [Eker and Kwakkel (2018)](https://doi.org/10.1016/j.envsoft.2018.03.029) introduced a more formal selection approach, the code of which can be found on [GitHub](https://github.com/sibeleker/MORDM---Multi-scenario-search). \n",
    "\n",
    "For this assignment, make an informed selection of 4 scenarios, using an approach of your choice. Motivate carefully your selection procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) import model and functionalities\n",
    "from ema_workbench import Model, RealParameter, ScalarOutcome, SequentialEvaluator, MultiprocessingEvaluator, ema_logging, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "import math\n",
    "def lake_problem_openloop(\n",
    "         b = 0.42,          # decay rate for P in lake (0.42 = irreversible)\n",
    "         q = 2.0,           # recycling exponent\n",
    "         mean = 0.02,       # mean of natural inflows\n",
    "         stdev = 0.001,     # future utility discount rate\n",
    "         delta = 0.98,      # standard deviation of natural inflows\n",
    "         \n",
    "         alpha = 0.4,       # utility from pollution\n",
    "         nsamples = 100,    # Monte Carlo sampling of natural inflows\n",
    "         timehorizon = 100, # simulation time\n",
    "         **kwargs):         \n",
    "\n",
    "    decisions = [kwargs[str(i)] for i in range(timehorizon)]\n",
    "    \n",
    "    Pcrit = brentq(lambda x: x**q/(1+x**q) - b*x, 0.01, 1.5)\n",
    "    nvars = int(timehorizon)\n",
    "    X = np.zeros((nvars,))\n",
    "    average_daily_P = np.zeros((nvars,))\n",
    "    decisions = np.array(decisions)\n",
    "\n",
    "    reliability = 0.0\n",
    "\n",
    "    for _ in range(nsamples):\n",
    "        X[0] = 0.0\n",
    "\n",
    "        natural_inflows = np.random.lognormal(\n",
    "                math.log(mean**2 / math.sqrt(stdev**2 + mean**2)),\n",
    "                math.sqrt(math.log(1.0 + stdev**2 / mean**2)),\n",
    "                size = nvars)\n",
    "  \n",
    "        for t in range(1,nvars):\n",
    "            \n",
    "            X[t] = (1-b)*X[t-1] + X[t-1]**q/(1+X[t-1]**q) +\\\n",
    "                    decisions[t-1] +\\\n",
    "                    natural_inflows[t-1]\n",
    "            average_daily_P[t] += X[t]/float(nsamples)\n",
    "        \n",
    "        reliability += np.sum(X < Pcrit)/float(nsamples*nvars)\n",
    "\n",
    "    utility = np.sum(alpha*decisions*np.power(delta,np.arange(nvars)))\n",
    "    inertia = np.sum(np.absolute(np.diff(decisions)) > 0.02)/float(nvars-1)\n",
    "      \n",
    "    max_P = np.max(average_daily_P)\n",
    "    return max_P, utility, inertia, reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#THE FUNCTION FOR ANTHROPOGENIC POLLUTION FOR CLOSED LOOP CONTROL\n",
    "def a_t(X, #x is a scalar, pollution at time t\n",
    "        c=[],\n",
    "        r=[],\n",
    "        w=[],\n",
    "        n=2):\n",
    "\n",
    "    a = sum([w[j]*(abs((X-c[j])/r[j]))**3 for j in range(n)])\n",
    "    return min(max(a, 0.01), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome, Constant)\n",
    "\n",
    "#instantiate the model\n",
    "lake_model = Model('lakeproblem', function=lake_problem_openloop)\n",
    "lake_model.time_horizon = 100\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers, one for each time step\n",
    "lake_model.levers = [RealParameter(str(i), 0, 0.1) for i in \n",
    "                     range(lake_model.time_horizon)]\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P', kind=ScalarOutcome.MINIMIZE),\n",
    "                       ScalarOutcome('utility', kind=ScalarOutcome.MAXIMIZE),\n",
    "                       ScalarOutcome('inertia', kind=ScalarOutcome.MINIMIZE),\n",
    "                       ScalarOutcome('reliability', kind=ScalarOutcome.MAXIMIZE)]\n",
    "\n",
    "# override some of the defaults of the model\n",
    "lake_model.constants = [Constant('alpha', 0.41),\n",
    "                        Constant('nsamples', 100),\n",
    "                        Constant('timehorizon', lake_model.time_horizon),\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 500 scenarios * 5 policies * 1 model(s) = 2500 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 250 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 750 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1250 cases completed\n",
      "[MainProcess/INFO] 1500 cases completed\n",
      "[MainProcess/INFO] 1750 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] 2250 cases completed\n",
      "[MainProcess/INFO] 2500 cases completed\n",
      "[MainProcess/INFO] experiments finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ema_workbench import (perform_experiments, ema_logging, save_results, \n",
    "                           load_results, Policy)\n",
    "from ema_workbench.em_framework import samplers\n",
    "from ema_workbench.em_framework import sample_levers\n",
    "\n",
    "# turn on logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# perform experiments\n",
    "nr_experiments = 500\n",
    "\n",
    "policies = sample_levers(lake_model,n_samples=5)\n",
    "results = perform_experiments(lake_model, nr_experiments, policies=policies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(             b     delta      mean         q     stdev         0         1  \\\n",
      "0     0.209223  0.949865  0.016252  2.626993  0.001617  0.027048  0.062200   \n",
      "1     0.143724  0.934551  0.010410  3.243318  0.001354  0.027048  0.062200   \n",
      "2     0.189700  0.973870  0.049288  3.542231  0.003501  0.027048  0.062200   \n",
      "3     0.188438  0.936908  0.024650  3.638312  0.004556  0.027048  0.062200   \n",
      "4     0.183939  0.970769  0.024241  4.485847  0.004281  0.027048  0.062200   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2495  0.361137  0.974617  0.044213  3.490575  0.004846  0.007165  0.020003   \n",
      "2496  0.265253  0.965550  0.045436  4.127214  0.003276  0.007165  0.020003   \n",
      "2497  0.249145  0.964041  0.020613  3.688882  0.001665  0.007165  0.020003   \n",
      "2498  0.111016  0.956735  0.018277  2.741777  0.004541  0.007165  0.020003   \n",
      "2499  0.241541  0.948323  0.044092  3.991799  0.001911  0.007165  0.020003   \n",
      "\n",
      "            10        11        12  ...        93        94        95  \\\n",
      "0     0.094435  0.016627  0.025077  ...  0.057259  0.083897  0.075037   \n",
      "1     0.094435  0.016627  0.025077  ...  0.057259  0.083897  0.075037   \n",
      "2     0.094435  0.016627  0.025077  ...  0.057259  0.083897  0.075037   \n",
      "3     0.094435  0.016627  0.025077  ...  0.057259  0.083897  0.075037   \n",
      "4     0.094435  0.016627  0.025077  ...  0.057259  0.083897  0.075037   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2495  0.049714  0.065156  0.044921  ...  0.072358  0.032354  0.021057   \n",
      "2496  0.049714  0.065156  0.044921  ...  0.072358  0.032354  0.021057   \n",
      "2497  0.049714  0.065156  0.044921  ...  0.072358  0.032354  0.021057   \n",
      "2498  0.049714  0.065156  0.044921  ...  0.072358  0.032354  0.021057   \n",
      "2499  0.049714  0.065156  0.044921  ...  0.072358  0.032354  0.021057   \n",
      "\n",
      "            96        97        98        99  scenario  policy        model  \n",
      "0     0.093782  0.051384  0.067246  0.024685         0       0  lakeproblem  \n",
      "1     0.093782  0.051384  0.067246  0.024685         1       0  lakeproblem  \n",
      "2     0.093782  0.051384  0.067246  0.024685         2       0  lakeproblem  \n",
      "3     0.093782  0.051384  0.067246  0.024685         3       0  lakeproblem  \n",
      "4     0.093782  0.051384  0.067246  0.024685         4       0  lakeproblem  \n",
      "...        ...       ...       ...       ...       ...     ...          ...  \n",
      "2495  0.067015  0.087643  0.095748  0.019905       495       4  lakeproblem  \n",
      "2496  0.067015  0.087643  0.095748  0.019905       496       4  lakeproblem  \n",
      "2497  0.067015  0.087643  0.095748  0.019905       497       4  lakeproblem  \n",
      "2498  0.067015  0.087643  0.095748  0.019905       498       4  lakeproblem  \n",
      "2499  0.067015  0.087643  0.095748  0.019905       499       4  lakeproblem  \n",
      "\n",
      "[2500 rows x 108 columns], {'max_P': array([5.08171407, 7.41496062, 5.83517943, ..., 4.33606523, 9.71892958,\n",
      "       4.60918749]), 'utility': array([0.41129071, 0.317516  , 0.71626198, ..., 0.55062153, 0.46322565,\n",
      "       0.38939583]), 'inertia': array([0.62626263, 0.62626263, 0.62626263, ..., 0.63636364, 0.63636364,\n",
      "       0.63636364]), 'reliability': array([0.0999, 0.1021, 0.09  , ..., 0.5233, 0.0519, 0.154 ])})\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Quakkels website\n",
    "Step 2.2: Select policy relevant scenarios based on the exploration results:\n",
    "   - max_P >= median(~ 5)\n",
    "   - reliability <= median (~0.5)\n",
    "   - inertia <= median (~1)\n",
    "   - utility <= median (~0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create four scenarios?\n",
    "# Step 2.2: Select policy relevant scenarios based on the exploration results:\n",
    "This was done in the paper by Kwakkel et al by tresholds for values calculated out of the outcomes, and then from these 4 maximally diverse scenarios are chosen to make sure that there is a big enoug representation of the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "oois = sorted(outcomes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_P': array([5.08171407, 7.41496062, 5.83517943, ..., 4.33606523, 9.71892958,\n",
      "       4.60918749]), 'utility': array([0.41129071, 0.317516  , 0.71626198, ..., 0.55062153, 0.46322565,\n",
      "       0.38939583]), 'inertia': array([0.62626263, 0.62626263, 0.62626263, ..., 0.63636364, 0.63636364,\n",
      "       0.63636364]), 'reliability': array([0.0999, 0.1021, 0.09  , ..., 0.5233, 0.0519, 0.154 ])}\n"
     ]
    }
   ],
   "source": [
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here, the policy-relevant scenarios defined by median thresholds are selected\n",
    "indices = []\n",
    "for ooi in oois:\n",
    "    if ooi in ['max_P', 'inertia']:\n",
    "        a = outcomes[ooi] > np.median(outcomes[ooi])     \n",
    "    else: \n",
    "        a = outcomes[ooi] < np.median(outcomes[ooi])\n",
    "    indices.append(a)\n",
    "indices = np.swapaxes(indices, 0, 1)\n",
    "logical_index = np.array([index.all() for index in indices])\n",
    "newExperiments = experiments[logical_index]\n",
    "newOutcomes = {}\n",
    "for ooi in oois:\n",
    "    newOutcomes[ooi] = outcomes[ooi][logical_index]\n",
    "newResults = newExperiments, newOutcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "print(len(newOutcomes['max_P']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results saved successfully to /Users/menghua/Documents/GitHub/FabiosDecisions/epa1361/Week-5-6-robustness-and-direct-search/206_experiments_openloop_Apollution.tar.gz\n"
     ]
    }
   ],
   "source": [
    "new_fn = '206_experiments_openloop_Apollution.tar.gz'\n",
    "save_results(newResults, new_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these results can be analyzed with the scenario-selection file.\n",
    "\n",
    "Results: maximum diversity and solutions: 1.0307457510054456, [[array([ 21,  28,  33, 104])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "#Find the Maximally diverse: \n",
    "import pandas as pd\n",
    "import copy\n",
    "#0 : non policy-relevant scenarios\n",
    "#1 : policy-relevant scenarios\n",
    "#2 : prim results\n",
    "#3 : diverse SELECTED\n",
    "#4 : random selected\n",
    "\n",
    "sel_column = logical_index.astype(int)\n",
    "selected = [ 21,  28,  33, 104]\n",
    "random_selected = [81, 289, 391, 257]\n",
    "count = 0\n",
    "for index, i in enumerate(sel_column):\n",
    "    \n",
    "    if logical_index[index]: #this is computed at the bottom of  the notebook\n",
    "        sel_column[index] = 2\n",
    "    if i:\n",
    "        if count in selected:\n",
    "            sel_column[index] = 3\n",
    "        count +=1 #the reason for the count is that the selected indices correspond to the dataset of 206 scenarios \n",
    "            \n",
    "    if index in random_selected:\n",
    "        sel_column[index] = 4\n",
    "        \n",
    "print(len(sel_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from /Users/menghua/Documents/GitHub/FabiosDecisions/epa1361/Week-5-6-robustness-and-direct-search/206_experiments_openloop_Apollution.tar.gz\n"
     ]
    }
   ],
   "source": [
    "scenario_results = load_results(\"206_experiments_openloop_Apollution.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = scenario_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25609548, 0.25666909, 0.25750083, 0.26049352])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.partition(outcomes[\"utility\"],4)[:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_utility = outcomes[\"utility\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 81, 95, 77]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_chosen = sorted(range(len(list_utility)), key=lambda k: list_utility[k])[:4]  \n",
    "sorted(range(len(list_utility)), key=lambda k: list_utility[k])[:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>delta</th>\n",
       "      <th>mean</th>\n",
       "      <th>q</th>\n",
       "      <th>stdev</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>scenario</th>\n",
       "      <th>policy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129391</td>\n",
       "      <td>0.930064</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>2.752705</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.021694</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.040714</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.102860</td>\n",
       "      <td>0.930224</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>3.965262</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.021694</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.040714</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>374</td>\n",
       "      <td>1</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.230517</td>\n",
       "      <td>0.930455</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>2.434750</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.021694</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.040714</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.137888</td>\n",
       "      <td>0.931273</td>\n",
       "      <td>0.027772</td>\n",
       "      <td>3.769088</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.021694</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.040714</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           b     delta      mean         q     stdev         0         1  \\\n",
       "4   0.129391  0.930064  0.021097  2.752705  0.004533  0.043022  0.013037   \n",
       "81  0.102860  0.930224  0.030264  3.965262  0.002708  0.043022  0.013037   \n",
       "95  0.230517  0.930455  0.044569  2.434750  0.001867  0.043022  0.013037   \n",
       "77  0.137888  0.931273  0.027772  3.769088  0.004754  0.043022  0.013037   \n",
       "\n",
       "          10        11        12  ...        93        94        95        96  \\\n",
       "4   0.021672  0.021694  0.009837  ...  0.013197  0.073614  0.059607  0.036734   \n",
       "81  0.021672  0.021694  0.009837  ...  0.013197  0.073614  0.059607  0.036734   \n",
       "95  0.021672  0.021694  0.009837  ...  0.013197  0.073614  0.059607  0.036734   \n",
       "77  0.021672  0.021694  0.009837  ...  0.013197  0.073614  0.059607  0.036734   \n",
       "\n",
       "          97        98        99  scenario  policy        model  \n",
       "4   0.004576  0.040714  0.044593        24       1  lakeproblem  \n",
       "81  0.004576  0.040714  0.044593       374       1  lakeproblem  \n",
       "95  0.004576  0.040714  0.044593       443       1  lakeproblem  \n",
       "77  0.004576  0.040714  0.044593       355       1  lakeproblem  \n",
       "\n",
       "[4 rows x 108 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_scenarios = experiments.iloc[list_chosen,:]\n",
    "selected_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_dictlist = selected_scenarios.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for each scenario\n",
    "\n",
    "For each of the four selected scenarios, use many-objective optimization to find a pareto approximate set using the same approach as for assignment 8. Remember to check for convergence (and time permitting, seed analysis), and be careful in what epsilon values to use (not to coarse, not too small). \n",
    "\n",
    "Store the resulting set of pareto solutions in a smart way for subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (RealParameter, ScalarOutcome, Constant,\n",
    "                           Model)\n",
    "from dps_lake_model import lake_model\n",
    "\n",
    "model = Model('lakeproblem', function=lake_model)\n",
    "\n",
    "#specify uncertainties\n",
    "model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                       RealParameter('q', 2.0, 4.5),\n",
    "                       RealParameter('mean', 0.01, 0.05),\n",
    "                       RealParameter('stdev', 0.001, 0.005),\n",
    "                       RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers\n",
    "model.levers = [RealParameter(\"c1\", -2, 2),\n",
    "                RealParameter(\"c2\", -2, 2),\n",
    "                RealParameter(\"r1\", 0, 2),\n",
    "                RealParameter(\"r2\", 0, 2),\n",
    "                RealParameter(\"w1\", 0, 1)]\n",
    "\n",
    "#specify outcomes\n",
    "model.outcomes = [ScalarOutcome('max_P', ScalarOutcome.MINIMIZE),\n",
    "                  ScalarOutcome('utility', ScalarOutcome.MAXIMIZE),\n",
    "                  ScalarOutcome('inertia', ScalarOutcome.MAXIMIZE),\n",
    "                  ScalarOutcome('reliability', ScalarOutcome.MAXIMIZE)]\n",
    "\n",
    "# override some of the defaults of the model\n",
    "model.constants = [Constant('alpha', 0.41),\n",
    "                   Constant('nsamples', 150),\n",
    "                   Constant('myears', 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Scenario\n",
    "scenario_1 = Scenario(\"1\", **scenarios_dictlist[0])\n",
    "scenario_2 = Scenario(\"2\", **scenarios_dictlist[1])\n",
    "scenario_3 = Scenario(\"3\", **scenarios_dictlist[2])\n",
    "scenario_4 = Scenario(\"4\", **scenarios_dictlist[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework.optimization import (HyperVolume,\n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench import Constraint\n",
    "\n",
    "constraints = [Constraint(\"max pollution\", outcome_names=\"max_P\",\n",
    "                          function=lambda x:max(0, x-1))]\n",
    "\n",
    "#constraints = [Constraint(\"max pollution\", outcome_names=\"max_P\",\n",
    "#                          function=lambda x:max(0, x-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_metrics = [HyperVolume(minimum=[0,0,0,0], maximum=[1,1.01,1.01,1.01]),\n",
    "                       EpsilonProgress()]\n",
    "\n",
    "#convergence_metrics = [HyperVolume( lake_model?? \n",
    "#                       EpsilonProgress()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] generation 0: 0/1000 nfe\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5fa9005f5fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mconvergence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvergence_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                     constraints=constraints, reference = scenario_1)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/ema_workbench/em_framework/evaluators.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, algorithm, nfe, searchover, reference, constraints, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m                         \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                         \u001b[0mconvergence_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvergence_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                         logging_freq=logging_freq, **kwargs)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     def robust_optimize(self, robustness_functions, scenarios,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/ema_workbench/em_framework/evaluators.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(models, algorithm, nfe, searchover, evaluator, reference, convergence, constraints, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     return _optimize(problem, evaluator, algorithm, convergence, nfe,\n\u001b[0;32m--> 538\u001b[0;31m                      convergence_freq, logging_freq, **kwargs)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/ema_workbench/em_framework/optimization.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(problem, evaluator, algorithm, convergence, nfe, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     with temporary_filter(name=[callbacks.__name__,\n\u001b[1;32m    828\u001b[0m                                 evaluators.__name__], level=INFO):\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     results = to_dataframe(optimizer, problem.parameter_names,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/platypus/core.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, condition, callback)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_frequency\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlast_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_frequency\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNSGAII\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/platypus/core.py\u001b[0m in \u001b[0;36mevaluate_all\u001b[0;34m(self, solutions)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_EvaluateJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munevaluated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# if needed, update the original solution with the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/ema_workbench/em_framework/evaluators.py\u001b[0m in \u001b[0;36mevaluate_all\u001b[0;34m(self, jobs, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msearchover\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'levers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uncertainties'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mevaluate_robust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/ema_workbench/em_framework/optimization.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(jobs_collection, experiments, outcomes, problem)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mlogical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         job_outcomes = {key: outcomes[key][logical][0]\n\u001b[0;32m--> 392\u001b[0;31m                         for key in outcome_names}\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# TODO:: only retain uncertainties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/gds/lib/python3.7/site-packages/ema_workbench/em_framework/optimization.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mlogical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         job_outcomes = {key: outcomes[key][logical][0]\n\u001b[0;32m--> 392\u001b[0;31m                         for key in outcome_names}\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# TODO:: only retain uncertainties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator\n",
    "from ema_workbench import ema_logging\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results_c, convergence = evaluator.optimize(nfe=1000, searchover='levers',\n",
    "                                    epsilons=[0.1, 0.1, 0.01, 0.1],\n",
    "                                    convergence=convergence_metrics,\n",
    "                                    constraints=constraints, reference = scenario_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_list = []\n",
    "solutions_list.append(results_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results_c, convergence = evaluator.optimize(nfe=1000, searchover='levers',\n",
    "                                    epsilons=[0.1, 0.1, 0.01, 0.1],\n",
    "                                    convergence=convergence_metrics,\n",
    "                                    constraints=constraints, reference = scenario_2)\n",
    "solutions_list.append(results_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results_c, convergence = evaluator.optimize(nfe=1000, searchover='levers',\n",
    "                                    epsilons=[0.1, 0.1, 0.01, 0.1],\n",
    "                                    convergence=convergence_metrics,\n",
    "                                    constraints=constraints, reference = scenario_3)\n",
    "solutions_list.append(results_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results_c, convergence = evaluator.optimize(nfe=1000, searchover='levers',\n",
    "                                    epsilons=[0.1, 0.1, 0.01, 0.1],\n",
    "                                    convergence=convergence_metrics,\n",
    "                                    constraints=constraints, reference = scenario_4)\n",
    "solutions_list.append(results_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate under deep uncertainty\n",
    "\n",
    "Combine the pareto set of solutions found for each scenario. Next, turn each solution into a policy object. If you have a very large number of policies, you can choose to down sample your policies in some reasoned way (*e.g.*, picking min and max on each objective, slicing across the pareto front with a particular step size). As a rule of thumb, try to limit the set of policies to at most 50. \n",
    "\n",
    "Re-evaluate the combined set of solutions over 1000 scenarios sampled using LHS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_solutions = pd.concat([solutions_list[0], solutions_list[1], solutions_list[2], solutions_list[3]])\n",
    "all_solutions = all_solutions.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = all_solutions.iloc[chosen_solutions,:].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_solutions = []\n",
    "chosen_solutions.append(all_solutions.max_P.idxmax())\n",
    "chosen_solutions.append(all_solutions.max_P.idxmin())\n",
    "chosen_solutions.append(all_solutions.utility.idxmax())\n",
    "chosen_solutions.append(all_solutions.utility.idxmin())\n",
    "chosen_solutions.append(all_solutions.inertia.idxmax())\n",
    "chosen_solutions.append(all_solutions.inertia.idxmin())\n",
    "chosen_solutions.append(all_solutions.reliability.idxmax())\n",
    "chosen_solutions.append(all_solutions.reliability.idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate both the maximum regret, and the domain criterion using the values provided in [Bartholomew and Kwakkel (2020)](https://doi.org/10.1016/j.envsoft.2020.104699). Ignore the max_P objective.\n",
    "\n",
    "visualize the results in parallel coordinate plot. \n",
    "\n",
    "Are there any promising compromise solutions which balance performance in both the reference scenarios as well as in terms of their robustness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_regret(data):\n",
    "    maximum = data.max()\n",
    "    regret = []\n",
    "    for value in data:\n",
    "        temp = maximum - value\n",
    "        regret.append(temp)\n",
    "    return max(regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

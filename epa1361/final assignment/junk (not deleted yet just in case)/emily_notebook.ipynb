{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Scenario, Policy, MultiprocessingEvaluator, ema_logging, load_results, save_results\n",
    "from ema_workbench.analysis import prim\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume,\n",
    "                                                     EpsilonProgress)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ema_workbench.analysis import parcoords\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTORNAME = \"Gorssel\"\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(ACTORNAME)\n",
    "outcomekeys = [outcome.name for outcome in dike_model.outcomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR = \"genscen_Gorssel_50000_12-06-2021-03-06-15.tar.gz\"\n",
    "experiments, outcomes = load_results(\"simulation/generated/\" + ACTOR)\n",
    "outcomes_df = pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAMAGE = outcomes_df.columns[2]\n",
    "DEATHS = outcomes_df.columns[3]\n",
    "COSTS = outcomes_df.columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([experiments, outcomes_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_damage_df = results.loc[results[DAMAGE] > np.percentile(a=outcomes[DAMAGE], q=90)]\n",
    "worst_deaths_df = results.loc[results[DEATHS] > np.percentile(a=outcomes[DEATHS], q=90)]\n",
    "worst_ix =set(worst_damage_df[\"scenario\"].tolist()) & set(worst_deaths_df[\"scenario\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_case = results.iloc[list(worst_ix)].sample(n=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_damage_df = results.loc[results[DAMAGE] <= np.percentile(a=outcomes[DAMAGE], q=10)]\n",
    "best_deaths_df = results.loc[results[DEATHS] <= np.percentile(a=outcomes[DEATHS], q=10)]\n",
    "best_ix = set(best_damage_df[\"scenario\"].tolist()) & set(best_deaths_df[\"scenario\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_case = results.iloc[list(best_ix)].sample(n=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinkage = results.loc[(results[DAMAGE] > np.percentile(a=outcomes[DAMAGE], q=25)) & (results[DAMAGE] <= np.percentile(a=outcomes[DAMAGE], q=75))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse = outcomes_df.index.isin(shrinkage[\"scenario\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_of_interest = outcomes_df[~inverse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outocme_of_interest = pd.DataFrame(outcomes_of_interest[[DAMAGE, DEATHS]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# normalize outcomes on unit interval to ensure equal weighting of outcomes\n",
    "x = outcomes_of_interest.values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_outcomes = pd.DataFrame(x_scaled, columns=outcomes_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "n_scen = experiments[~inverse].shape[0]\n",
    "indices = range(n_scen)\n",
    "set_size = 3\n",
    "n_scen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "n_scen = experiments[~inverse].shape[0]\n",
    "indices = range(n_scen)\n",
    "set_size = 3\n",
    "n_scen\n",
    "combinations = itertools.combinations(indices, set_size)\n",
    "combinations = list(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def evaluate_diversity_single(indices, distances, weight=0.5, distance='euclidean'):\n",
    "    '''\n",
    "    takes the outcomes and selected scenario set (decision variables), \n",
    "    returns a single 'diversity' value for the scenario set.\n",
    "    outcomes : outcomes dictionary of the scenario ensemble\n",
    "    decision vars : indices of the scenario set\n",
    "    weight : weight given to the mean in the diversity metric. If 0, only minimum; if 1, only mean\n",
    "    '''\n",
    "    i, j = [e for e in zip(*itertools.combinations(indices, 2))]\n",
    "    subset_distances = distances[i, j]\n",
    "    minimum = np.min(subset_distances)\n",
    "    mean = np.mean(subset_distances)\n",
    "    diversity = (1-weight)*minimum + weight*mean\n",
    "    \n",
    "    return [diversity]\n",
    "\n",
    "\n",
    "def find_maxdiverse_scenarios(distances, combinations):\n",
    "    scores = []\n",
    "    for indices in combinations:\n",
    "        diversity = evaluate_diversity_single(indices, distances)\n",
    "        scores.append((diversity, indices))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import functools\n",
    "\n",
    "distances = squareform(pdist(normalized_outcomes.values))\n",
    "\n",
    "cores = os.cpu_count()\n",
    "partial_function = functools.partial(find_maxdiverse_scenarios, distances)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=cores) as executor:\n",
    "    worker_data = np.array_split(combinations, cores)\n",
    "    results = [e for e in executor.map(partial_function, worker_data)]\n",
    "    results = list(itertools.chain.from_iterable(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key=lambda entry:entry[0], reverse=True)\n",
    "most_diverse = results[0]\n",
    "most_diverse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

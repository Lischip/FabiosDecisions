{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "demanding-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Scenario\n",
    "from ema_workbench.analysis import prim\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "from ema_workbench import load_results\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume,\n",
    "                                                     EpsilonProgress)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modern-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dike_model, planning_steps = get_model_for_problem_formulation(\"Gorssel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-storage",
   "metadata": {},
   "source": [
    "# Scenario selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "collected-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR = \"genscen_Gorssel_50000_08-06-2021-01-09-07.tar.gz\"\n",
    "experiments, outcomes = load_results(\"data/generated/\" + ACTOR)\n",
    "outcomes_df = pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opening-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Difference in Expected Annual Damage Gorssel-Deventer',\n",
       " 'Difference in Expected Number of Deaths Gorssel-Deventer',\n",
       " 'Expected Annual Damage Gorssel']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes_df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "special-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFDAMAGE = outcomes_df.columns[0]\n",
    "DIFDEATHS = outcomes_df.columns[1]\n",
    "DAMAGE = outcomes_df.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stupid-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([experiments, outcomes_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rolled-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damage_df = results.loc[results[DAMAGE] > np.percentile(a=outcomes[DAMAGE], q=90)]\n",
    "difdamage_df = results.loc[results[DIFDAMAGE] > np.percentile(a=outcomes[DIFDAMAGE], q=90)]\n",
    "difdeaths_df = results.loc[results[DIFDEATHS] > np.percentile(a=outcomes[DIFDEATHS], q=90)]\n",
    "len(set(damage_df[\"scenario\"].tolist()) & set(difdamage_df[\"scenario\"].tolist()) & set(difdeaths_df[\"scenario\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "analyzed-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [damage_df.sample(n=1, random_state=1), difdamage_df.sample(n=1, random_state=1), difdeaths_df.sample(n=1, random_state=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [Scenario(f\"{index}\", **row) for index, row in selected.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-patient",
   "metadata": {},
   "source": [
    "# Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "def optimize(scenario, nfe, model, converge_metrics, epsilons):\n",
    "\n",
    "\n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        results, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                     convergence=convergence_metrics,\n",
    "                                     epsilons=epsilons,\n",
    "                                     reference=scenario)\n",
    "    return results, convergence\n",
    "\n",
    "\n",
    "results = []\n",
    "for scenario in scenarios:\n",
    "    convergence_metrics = [HyperVolume(minimum=[0,0,0,0], maximum=[3, 2,1.01,1.01]),\n",
    "                           EpsilonProgress()]\n",
    "    epsilons = [0.1,]*len(model.outcomes)\n",
    "    \n",
    "    results.append(optimize(scenario, 1e4, dike_model, convergence_metrics, epsilons))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-funeral",
   "metadata": {},
   "source": [
    "# Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-module",
   "metadata": {},
   "source": [
    "# Satisficing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Scenario MORDM\n",
    "\n",
    "Multi-scenario MORMD is an extension of normal MORDM to better include robustness considerations within the search phase. It starts from the scenario discovery results resulting from MORDM. Next, from the experiments within this box, a set of scenarios is selected. \n",
    "\n",
    "There are many ways of selecting the additional scenarios. The original paper which introduced multi-scenario MORMD [Watson and Kaspzryk (2017)](https://doi.org/10.1016/j.envsoft.2016.12.001) did it in a more or less adhoc manner. [Eker and Kwakkel (2018)](https://doi.org/10.1016/j.envsoft.2018.03.029) introduced a more formal selection approach, the code of which can be found on [GitHub](https://github.com/sibeleker/MORDM---Multi-scenario-search). \n",
    "\n",
    "For this assignment, make an informed selection of 4 scenarios, using an approach of your choice. Motivate carefully your selection procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) import model and functionalities\n",
    "from dps_lake_model import lake_model\n",
    "from ema_workbench import Model, RealParameter, ScalarOutcome, SequentialEvaluator, MultiprocessingEvaluator, ema_logging, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#THE FUNCTION FOR ANTHROPOGENIC POLLUTION FOR CLOSED LOOP CONTROL\n",
    "def a_t(X, #x is a scalar, pollution at time t\n",
    "        c=[],\n",
    "        r=[],\n",
    "        w=[],\n",
    "        n=2):\n",
    "\n",
    "    a = sum([w[j]*(abs((X-c[j])/r[j]))**3 for j in range(n)])\n",
    "    return min(max(a, 0.01), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome, Constant)\n",
    "\n",
    "# 2) create ema_workbench\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "lake_model = Model('lakeproblem', function=lake_model)\n",
    "lake_model.time_horizon = 100 \n",
    "\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "#set levers\n",
    "lake_model.levers = [RealParameter(\"c1\", -2, 2),\n",
    "                     RealParameter(\"c2\", -2, 2),\n",
    "                     RealParameter(\"r1\", 0, 2),\n",
    "                     RealParameter(\"r2\", 0, 2),\n",
    "                     RealParameter(\"w1\", 0, 1)]\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P', kind=ScalarOutcome.MINIMIZE),\n",
    "                       ScalarOutcome('utility', kind=ScalarOutcome.MAXIMIZE),\n",
    "                       ScalarOutcome('inertia', kind=ScalarOutcome.MAXIMIZE),\n",
    "                       ScalarOutcome('reliability', kind=ScalarOutcome.MAXIMIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 500 scenarios * 5 policies * 1 model(s) = 2500 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 250 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 750 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1250 cases completed\n",
      "[MainProcess/INFO] 1500 cases completed\n",
      "[MainProcess/INFO] 1750 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] 2250 cases completed\n",
      "[MainProcess/INFO] 2500 cases completed\n",
      "[MainProcess/INFO] experiments finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ema_workbench import (perform_experiments, ema_logging, save_results, \n",
    "                           load_results, Policy)\n",
    "from ema_workbench.em_framework import samplers\n",
    "from ema_workbench.em_framework import sample_levers\n",
    "\n",
    "# turn on logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# perform experiments\n",
    "nr_experiments = 500\n",
    "\n",
    "policies = sample_levers(lake_model,n_samples=5)\n",
    "results = perform_experiments(lake_model, nr_experiments, policies=policies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(             b     delta      mean         q     stdev        c1        c2  \\\n",
      "0     0.120606  0.968628  0.011958  4.318904  0.002908 -0.411316  1.961893   \n",
      "1     0.173320  0.964136  0.017475  3.096429  0.002273 -0.411316  1.961893   \n",
      "2     0.378114  0.963297  0.026193  3.373834  0.001684 -0.411316  1.961893   \n",
      "3     0.395483  0.960449  0.045103  4.012244  0.003457 -0.411316  1.961893   \n",
      "4     0.365285  0.942945  0.022120  3.426001  0.001534 -0.411316  1.961893   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2495  0.260811  0.938482  0.043456  3.710358  0.001451 -0.267186 -1.124323   \n",
      "2496  0.297825  0.949672  0.027371  4.496056  0.004690 -0.267186 -1.124323   \n",
      "2497  0.216185  0.965533  0.013325  2.699545  0.004381 -0.267186 -1.124323   \n",
      "2498  0.225889  0.966917  0.049569  2.101946  0.004533 -0.267186 -1.124323   \n",
      "2499  0.117361  0.959510  0.028579  3.342391  0.003090 -0.267186 -1.124323   \n",
      "\n",
      "            r1        r2        w1 scenario policy        model  \n",
      "0     0.637405  0.960882  0.593583        0      0  lakeproblem  \n",
      "1     0.637405  0.960882  0.593583        1      0  lakeproblem  \n",
      "2     0.637405  0.960882  0.593583        2      0  lakeproblem  \n",
      "3     0.637405  0.960882  0.593583        3      0  lakeproblem  \n",
      "4     0.637405  0.960882  0.593583        4      0  lakeproblem  \n",
      "...        ...       ...       ...      ...    ...          ...  \n",
      "2495  1.844939  1.539844  0.748776      495      4  lakeproblem  \n",
      "2496  1.844939  1.539844  0.748776      496      4  lakeproblem  \n",
      "2497  1.844939  1.539844  0.748776      497      4  lakeproblem  \n",
      "2498  1.844939  1.539844  0.748776      498      4  lakeproblem  \n",
      "2499  1.844939  1.539844  0.748776      499      4  lakeproblem  \n",
      "\n",
      "[2500 rows x 13 columns], {'max_P': array([9.2195883 , 6.43005504, 2.90865227, ..., 5.0945037 , 4.9411942 ,\n",
      "       9.61281639]), 'utility': array([1.22238325, 1.08641475, 1.06392649, ..., 1.12575498, 1.16727088,\n",
      "       0.97206268]), 'inertia': array([0.99, 0.99, 0.99, ..., 0.99, 0.99, 0.99]), 'reliability': array([0.0608, 0.05  , 0.1969, ..., 0.05  , 0.0209, 0.04  ])})\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Quakkels website\n",
    "Step 2.2: Select policy relevant scenarios based on the exploration results:\n",
    "   - max_P >= median(~ 5)\n",
    "   - reliability <= median (~0.5)\n",
    "   - inertia <= median (~1)\n",
    "   - utility <= median (~0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create four scenarios?\n",
    "# Step 2.2: Select policy relevant scenarios based on the exploration results:Â¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "oois = sorted(outcomes.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_P': array([9.2195883 , 6.43005504, 2.90865227, ..., 5.0945037 , 4.9411942 ,\n",
      "       9.61281639]), 'utility': array([1.22238325, 1.08641475, 1.06392649, ..., 1.12575498, 1.16727088,\n",
      "       0.97206268]), 'inertia': array([0.99, 0.99, 0.99, ..., 0.99, 0.99, 0.99]), 'reliability': array([0.0608, 0.05  , 0.1969, ..., 0.05  , 0.0209, 0.04  ])}\n"
     ]
    }
   ],
   "source": [
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here, the policy-relevant scenarios defined by median thresholds are selected\n",
    "indices = []\n",
    "for ooi in oois:\n",
    "    if ooi in ['max_P', 'inertia']:\n",
    "        a = outcomes[ooi] > np.median(outcomes[ooi])     \n",
    "    else: \n",
    "        a = outcomes[ooi] < np.median(outcomes[ooi])\n",
    "    indices.append(a)\n",
    "indices = np.swapaxes(indices, 0, 1)\n",
    "logical_index = np.array([index.all() for index in indices])\n",
    "newExperiments = experiments[logical_index]\n",
    "newOutcomes = {}\n",
    "for ooi in oois:\n",
    "    newOutcomes[ooi] = outcomes[ooi][logical_index]\n",
    "newResults = newExperiments, newOutcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(newOutcomes['max_P']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for each scenario\n",
    "\n",
    "For each of the four selected scenarios, use many-objective optimization to find a pareto approximate set using the same approach as for assignment 8. Remember to check for convergence (and time permitting, seed analysis), and be careful in what epsilon values to use (not to coarse, not too small). \n",
    "\n",
    "Store the resulting set of pareto solutions in a smart way for subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate under deep uncertainty\n",
    "\n",
    "Combine the pareto set of solutions found for each scenario. Next, turn each solution into a policy object. If you have a very large number of policies, you can choose to down sample your policies in some reasoned way (*e.g.*, picking min and max on each objective, slicing across the pareto front with a particular step size). As a rule of thumb, try to limit the set of policies to at most 50. \n",
    "\n",
    "Re-evaluate the combined set of solutions over 1000 scenarios sampled using LHS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate both the maximum regret, and the domain criterion using the values provided in [Bartholomew and Kwakkel (2020)](https://doi.org/10.1016/j.envsoft.2020.104699). Ignore the max_P objective.\n",
    "\n",
    "visualize the results in parallel coordinate plot. \n",
    "\n",
    "Are there any promising compromise solutions which balance performance in both the reference scenarios as well as in terms of their robustness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
